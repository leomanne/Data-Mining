{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourth Task: Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import of the needed libraries and the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "import pydotplus \n",
    "from IPython.display import Image  \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cyclists = pd.read_csv('./dataset/cyclists_trasformed.csv')\n",
    "races = pd.read_csv('./dataset/races_trasformed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before employing the learning algorithms, we need to perform a few adjustments to our data. \n",
    "\n",
    "Firstly, it is necessary to merge the two dataset and delete not useful columns for the purpose.\n",
    "\n",
    "Then, we will add an attribute for specifying if a certain cyclist was in the first 20 position of a race or not. \n",
    "\n",
    "We delete:\n",
    "\n",
    "• *name* (coming from cyclist), since it is a repetition for *_url* in cyclist\n",
    "\n",
    "• *name* (coming from races), since it is a repetition for *_url* in races\n",
    "\n",
    "• *weight* and *height* (coming from cyclist), since these characteristics are combined in the *bmi* feature we created \n",
    "\n",
    "• *avg_position* and *avg_delta* (coming from cyclist), since it is better to consider more precise columns like *position* (see next) and *delta* from races\n",
    "\n",
    "• *position* (coming from races) since we consider only the first 20 we will get from the new column \n",
    "\n",
    "• *birth_year* (coming from cyclist) because it's redundant having *cyclist_age* from races\n",
    "\n",
    "• *cyclist_team* (coming from races) since we consider single cyclists\n",
    "\n",
    "• *date* (coming from races) whose format is: \"YYYY-MM-DD HH-MM-SS\". From it, we can extract the information we need: we exclude the \"HH-MM-SS\" and the \"MM-DD\" part because we can easily group races based on the *season* of the year (attribute that we already have). At the end, we only care about the year for splitting the races for the training set.\n",
    "\n",
    "We add:\n",
    "\n",
    "• *top_20*, having value =1 if the corresponding cyclist was in between these positions or, on the opposite, =0.\n",
    "\n",
    "**NB**: we drop *position* after creating the column *top_20*, since it is needed to fill the new one correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge\n",
    "data_merged = pd.merge(races, cyclists, left_on='cyclist', right_on='_url', how='outer', indicator=True)\n",
    "\n",
    "#Filter non-corresponding rows: these cyclists never participate to a competition, so we don't consider them either for the prediction\n",
    "mismatched = data_merged[data_merged['_merge'] != 'both']\n",
    "print(f\"Number of mismatched entries: {len(mismatched)}\")\n",
    "print(mismatched)\n",
    "\n",
    "#Drop \n",
    "data_merged = data_merged[data_merged['_merge'] == 'both']\n",
    "\n",
    "#Drop the '_merge' column as it's no longer needed\n",
    "data_merged.drop('_merge', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the specification, we create the new attribute *top_20* where the value is '1' if in the row the attribute *position* ranges from 0 to 19, '0' otherwise. \n",
    "\n",
    "As stated before, we drop *position* since is useless from now on and modify *date* so that it contains only the year. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename '_url_x' in 'race_url' and '_url_y' in 'cyclist_url'\n",
    "data_merged.rename(columns={'_url_x': 'race_url', '_url_y':'cyclist_url'}, inplace=True)\n",
    "\n",
    "#Delete useless columns we cited, except position\n",
    "data_merged = data_merged.drop(columns=['name_x', 'name_y', 'cyclist', 'weight', 'height', 'birth_year', 'avg_position', 'avg_delta', 'cyclist_team'])\n",
    "\n",
    "#Create 'top_20'\n",
    "data_merged['top_20'] = (data_merged['position'] < 20).astype(int)\n",
    "\n",
    "#Drop position \n",
    "data_merged = data_merged.drop(columns=['position']) \n",
    "\n",
    "data_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning algorithms require the categorical data to be transformed into numerical ones.\n",
    "\n",
    "In order to do this, we define the following function that assign a number for each different value inside the \n",
    "attribute starting from 1 and substitutes the categorical.  \n",
    "\n",
    "We cast the boolean values for *is_tarmac* to int. \n",
    "\n",
    "At the end, we are ready to define our 'train_set' and 'test_set' variables based on the year we get from *date*:\n",
    "\n",
    "- Training set: needed to train models.\n",
    "- Test set: need to test the model on never-seen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to discretize the variables\n",
    "#Input: the dataset and the list of variables' names to discretize\n",
    "def discretize_data(dataset, variables):\n",
    "    for variable in variables:\n",
    "        #Get the unique variable's values\n",
    "        var = sorted(dataset[variable].unique())\n",
    "        #Generate a mapping from the variable's values to the number representation  \n",
    "        mapping = dict(zip(var, range(0, len(var) + 1)))\n",
    "        dataset[variable] = dataset[variable].map(mapping).astype(int)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attribute to transform\n",
    "categorical_variables = ['race_url', 'season', 'cyclist_url', 'nationality', 'continent']\n",
    "data_merged = discretize_data(data_merged, categorical_variables)\n",
    "\n",
    "#Other casting\n",
    "data_merged['is_tarmac'] = data_merged['is_tarmac'].astype(int)\n",
    "data_merged['date'] = pd.DatetimeIndex(data_merged['date']).year\n",
    "\n",
    "#Training set\n",
    "train_data = data_merged[data_merged['date'] < 2022]\n",
    "#Test set\n",
    "test_data = data_merged[data_merged['date'] >= 2022]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our machine learning purpose, the dataset has to be divided into two parts:\n",
    "\n",
    "- Features (x): The input data containing the information needed by the model to make predictions (every attribute except *top_20*)\n",
    "- Target (y): The output data you want the model to predict (precisely *top_20*).\n",
    "\n",
    "So, we create two variables for both *train_data* and *test_data*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature(x) and target(y) for training\n",
    "x_train = train_data.drop(columns=['top_20'])\n",
    "y_train = train_data['top_20']\n",
    "\n",
    "#Feature(x) and target(y) for testing\n",
    "x_test = test_data.drop(columns=['top_20'])\n",
    "y_test = test_data['top_20']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models we choose can be divided in different categories:\n",
    "\n",
    "1) Tree-Based Models (Decision Tree, Random Forest)\n",
    "\n",
    "2) AdaBoost\n",
    "\n",
    "3) Naïve Bayes\n",
    "\n",
    "4) K-Nearest Neighbors (KNN)\n",
    "\n",
    "5) Neural Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`NB`: We tried to implement XGBoost, Rule-Based and SVM but after 15 minutes the methods were still running. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_scores(test_label, test_pred):\n",
    "    print(classification_report(test_label, \n",
    "                            test_pred, \n",
    "                            target_names=['Non-Top 20', 'Top 20']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree-Based Models (Decision Tree, Random Forest, AdaBoost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating and configuring the Decision Tree\n",
    "dt = tree.DecisionTreeClassifier(\n",
    "    criterion='gini',               #Use the Gini index to evaluate the purity of splits\n",
    "    splitter='best',                #Splits the nodes by choosing the best split\n",
    "    class_weight='balanced',         \n",
    "    max_depth=5,                    #Limit tree depth to 5 levels\n",
    "    min_samples_split=3,            #A node must have at least 3 samples to be split\n",
    "    min_samples_leaf=4,             #Each leaf must contain at least 4 examples\n",
    "    random_state=42                 #Ensures repeatability of results\n",
    ")\n",
    "\n",
    "#Train the model\n",
    "dt = dt.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the actual Decision Tree obtained: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To visualize the Decision Tree, you must intsall GraphViz\n",
    "#MacOs: brew install graphviz\n",
    "#Linux: sudo apt-get install graphviz\n",
    "#Windows: Install from here https://graphviz.org/download/ \n",
    "#and add the following enviroment variable (the path can change)\n",
    "#import os\n",
    "#os.environ[\"PATH\"] += os.pathsep + 'C:\\Program Files (x86)\\Graphviz2.38/bin/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(dt, out_file=None, \n",
    "                                feature_names=list(x_train.columns),  \n",
    "                                class_names=['Non-Top 20', 'Top 20'],  \n",
    "                                filled=True, rounded=True)  \n",
    "graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "Image(graph.create_png())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction over test dataset employing Decision Tree\n",
    "test_pred_dt = dt.predict(x_test)    \n",
    "\n",
    "#Compute the performance of the model\n",
    "report_scores(y_test, test_pred_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to read the result:\n",
    "- **Non-Top 20**: \n",
    "    - Precision: 0.95 - Of all the predictions that the model classified as ‘Non-Top 20’, 95% were correct.\n",
    "    - Recall: 0.75: 75% of the riders actually ‘Non-Top 20’ were correctly identified by the model.\n",
    "    - F1-Score: 0.84 - Represents the balance between precision and recall, and is very high for this class, indicating that the model is excellent at correctly distinguishing ‘Non-Top 20’ cyclists.\n",
    "    - Support: 30.466 - Indicates the total number of true samples belonging to the ‘Non-Top 20’ class.\n",
    "- **Top 20**: \n",
    "    - Precision: 0.33 - Of all predictions classified as ‘Top 20’, only 33% are correct. This indicates that the model tends to include false positives.\n",
    "    - Recall: 0.77 - 77% of the cyclists actually in the ‘Top 20’ were recognised correctly. \n",
    "    - F1-Score: 0.46 - Being the balance between precision and recall, the mid-low value suggests that the model has difficulty with the ‘Top 20’ class.\n",
    "    - Support: 4.940 - Indicates the total number of true samples belonging to the ‘Top 20’ class.\n",
    "- **Accuracy** \n",
    "    - Accuracy: 0.75 - Percentage of correct predictions out of the total data. Although the value is high, it is influenced by the strong dominance of the Non-Top 20 class (majority class).\n",
    "- **Macro Average**\n",
    "    - Precision: 0.64 - Arithmetic mean of the precision of the two classes.\n",
    "    - Recall: 0.76 - Arithmetic mean of the recall of the two classes. Low due to extremely low recall for the ‘Top 20’ class.\n",
    "    - F1-Score: 0.65 - Arithmetic mean of the F1-Score of the two classes. Reflects the difficulty of the model in handling the ‘Top 20’ class.\n",
    "- **Weighted Average**.\n",
    "    - Precision: 0.87 - Weighted average of the precision, considering the support (size) of each class.\n",
    "    - Recall: 0.75 - Weighted average of recall, strongly influenced by the high recall of the ‘Non-Top 20’ class.\n",
    "    - F1-Score: 0.79 - Weighted average of the F1-Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute and visualize Confusion Matrix\n",
    "cm = confusion_matrix(y_test, test_pred_dt)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=dt.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to read the results:\n",
    "\n",
    "- True Negatives (TN): 22794 - Correct predictions for class 0.\n",
    "\n",
    "- False Positives (FP): 7672 - Incorrect predictions that indicated 1 instead of 0.\n",
    "\n",
    "- False Negatives (FN): 1132 - Incorrect predictions that indicated 0 instead of 1.\n",
    "\n",
    "- True Positives (TP): 3808 - Correct predictions for class 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest definition and training\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100, #Number of trees in the forest\n",
    "    criterion='gini', #Measure to evaluate the purity of the split\n",
    "    class_weight='balanced', #Automatically calculates inverse weights to class frequencies (The class with fewer samples receives a higher weight)\n",
    "    max_depth=10, #Maximum depth of trees\n",
    "    min_samples_split=5, #Minimum number of samples to split a node\n",
    "    random_state=42, #Ensures repeatability of results\n",
    ")\n",
    "\n",
    "#Model training\n",
    "rf = rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction employing Random Forest\n",
    "test_pred_rf = rf.predict(x_test)    \n",
    "\n",
    "#Compute the performance of the model\n",
    "report_scores(y_test, test_pred_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to read the result:\n",
    "- **Non-Top 20**: \n",
    "    - Precision: 0.96 - Of all the predictions that the model classified as ‘Non-Top 20’, 88% were correct.\n",
    "    - Recall: 0.81: 81% of the riders actually ‘Non-Top 20’ were correctly identified by the model.\n",
    "    - F1-Score: 0.88 - Represents the balance between precision and recall, and is very high for this class, indicating that the model is excellent at correctly distinguishing ‘Non-Top 20’ cyclists.\n",
    "    - Support: 30.466 - Indicates the total number of true samples belonging to the ‘Non-Top 20’ class.\n",
    "- **Top 20**: \n",
    "    - Precision: 0.40 - Of all predictions classified as ‘Top 20’, only 40% are correct. This indicates that the model tends to include false positives.\n",
    "    - Recall: 0.79 - 79% of the cyclists actually in the ‘Top 20’ were recognised correctly. \n",
    "    - F1-Score: 0.53 - Being the balance between precision and recall, the mid-low value suggests that the model has difficulty with the ‘Top 20’ class.\n",
    "    - Support: 4.940 - Indicates the total number of true samples belonging to the ‘Top 20’ class.\n",
    "- **Accuracy** \n",
    "    - Accuracy: 0.81 - Percentage of correct predictions out of the total data. Although the value is high, it is influenced by the strong dominance of the Non-Top 20 class (majority class).\n",
    "- **Macro Average**\n",
    "    - Precision: 0.68 - Arithmetic mean of the precision of the two classes.\n",
    "    - Recall: 0.80 - Arithmetic mean of the recall of the two classes. \n",
    "    - F1-Score: 0.71 - Arithmetic mean of the F1-Score of the two classes. \n",
    "- **Weighted Average**.\n",
    "    - Precision: 0.88 - Weighted average of the precision, considering the support (size) of each class.\n",
    "    - Recall: 0.81 - Weighted average of recall, strongly influenced by the high recall of the ‘Non-Top 20’ class.\n",
    "    - F1-Score: 0.83 - Weighted average of the F1-Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute and visualize Confusion Matrix\n",
    "cm = confusion_matrix(y_test, test_pred_rf)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=rf.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to read the results:\n",
    "\n",
    "- True Negatives (TN): 24684 - Correct predictions for class 0.\n",
    "\n",
    "- False Positives (FP): 5782 - Incorrect predictions that indicated 1 instead of 0.\n",
    "\n",
    "- False Negatives (FN): 1042 - Incorrect predictions that indicated 0 instead of 1.\n",
    "\n",
    "- True Positives (TP): 3898 - Correct predictions for class 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final comparisons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary containing trained models\n",
    "models = {\n",
    "    \"Decision Tree\": dt,          \n",
    "    \"Random Forest\": rf   \n",
    "}\n",
    "\n",
    "#Iteration on models to calculate and print metrics\n",
    "for model_name, model in models.items():\n",
    "    y_test_pred = model.predict(x_test)\n",
    "    acc = accuracy_score(y_test, y_test_pred)\n",
    "    conf = confusion_matrix(y_test, y_test_pred)\n",
    "    report = classification_report(y_test, y_test_pred, target_names=[\"Non Top 20\", \"Top 20\"], zero_division=0)\n",
    "    print(f\"\\n--- {model_name} ---\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{conf}\")\n",
    "    print(f\"Classification Report:\\n{report}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train AdaBoost with default settings\n",
    "\n",
    "clf = AdaBoostClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "test_pred_clf = clf.predict(x_test)\n",
    "print(classification_report(y_test, test_pred_clf, target_names=['Non-Top 20', 'Top 20']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to read the result:\n",
    "- **Non-Top 20**: \n",
    "    - Precision: 0.88 - Of all the predictions that the model classified as ‘Non-Top 20’, 88% were correct.\n",
    "    - Recall: 0.98: 98% of the riders actually ‘Non-Top 20’ were correctly identified by the model.\n",
    "    - F1-Score: 0.93 - Represents the balance between precision and recall, and is very high for this class, indicating that the model is excellent at correctly distinguishing ‘Non-Top 20’ cyclists.\n",
    "    - Support: 30.466 - Indicates the total number of true samples belonging to the ‘Non-Top 20’ class.\n",
    "- **Top 20**: \n",
    "    - Precision: 0.63 - Of all predictions classified as ‘Top 20’, only 63% are correct. This indicates that the model tends to include false positives.\n",
    "    - Recall: 0.19 - Only 19% of the cyclists actually in the ‘Top 20’ were recognised correctly. This indicates that the model is not effective in capturing true positives in this class.\n",
    "    - F1-Score: 0.29 - Being the balance between precision and recall, the low value suggests that the model has difficulty with the ‘Top 20’ class.\n",
    "    - Support: 4.940 - Indicates the total number of true samples belonging to the ‘Top 20’ class.\n",
    "- **Accuracy** \n",
    "    - Accuracy: 0.87 - Percentage of correct predictions out of the total data. Although the value is high, it is influenced by the strong dominance of the Non-Top 20 class (majority class).\n",
    "- **Macro Average**\n",
    "    - Precision: 0.75 - Arithmetic mean of the precision of the two classes.\n",
    "    - Recall: 0.58 - Arithmetic mean of the recall of the two classes. Low due to extremely low recall for the ‘Top 20’ class.\n",
    "    - F1-Score: 0.61 - Arithmetic mean of the F1-Score of the two classes. Reflects the difficulty of the model in handling the ‘Top 20’ class.\n",
    "- **Weighted Average**.\n",
    "    - Precision: 0.87 - Weighted average of the precision, considering the support (size) of each class.\n",
    "    - Recall: 0.87 - Weighted average of recall, strongly influenced by the high recall of the ‘Non-Top 20’ class.\n",
    "    - F1-Score: 0.84 - Weighted average of the F1-Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute and visualize Confusion Matrix\n",
    "cm = confusion_matrix(y_test, test_pred_clf)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=rf.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to read the results:\n",
    "\n",
    "- True Negatives (TN): 29909 - Correct predictions for class 0.\n",
    "\n",
    "- False Positives (FP): 557 - Incorrect predictions that indicated 1 instead of 0.\n",
    "\n",
    "- False Negatives (FN): 4011 - Incorrect predictions that indicated 0 instead of 1.\n",
    "\n",
    "- True Positives (TP): 929 - Correct predictions for class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train AdaBoost with a custom base estimator and hyperparameters\n",
    "\n",
    "base = DecisionTreeClassifier(max_depth=5)\n",
    "clf = AdaBoostClassifier(estimator=base, n_estimators=200, learning_rate=0.1)\n",
    "clf.fit(x_train, y_train)\n",
    "test_pred_clf = clf.predict(x_test)\n",
    "print(\"Custom AdaBoost Classifier with DecisionTree base:\")\n",
    "print(classification_report(y_test, test_pred_clf, target_names=['Non-Top 20', 'Top 20']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to read the result:\n",
    "- **Non-Top 20**: \n",
    "    - Precision: 0.92 - Of all the predictions that the model classified as ‘Non-Top 20’, 92% were correct.\n",
    "    - Recall: 0.95: 95% of the riders actually ‘Non-Top 20’ were correctly identified by the model.\n",
    "    - F1-Score: 0.93 - Represents the balance between precision and recall, and is very high for this class, indicating that the model is excellent at correctly distinguishing ‘Non-Top 20’ cyclists.\n",
    "    - Support: 30.466 - Indicates the total number of true samples belonging to the ‘Non-Top 20’ class.\n",
    "- **Top 20**: \n",
    "    - Precision: 0.59 - Of all predictions classified as ‘Top 20’, only 59% are correct. This indicates that the model tends to include false positives.\n",
    "    - Recall: 0.47 - Only 47% of the cyclists actually in the ‘Top 20’ were recognised correctly. \n",
    "    - F1-Score: 0.52 - Being the balance between precision and recall, the low value suggests that the model has difficulty with the ‘Top 20’ class.\n",
    "    - Support: 4.940 - Indicates the total number of true samples belonging to the ‘Top 20’ class.\n",
    "- **Accuracy** \n",
    "    - Accuracy: 0.88 - Percentage of correct predictions out of the total data. Although the value is high, it is influenced by the strong dominance of the Non-Top 20 class (majority class).\n",
    "- **Macro Average**\n",
    "    - Precision: 0.75 - Arithmetic mean of the precision of the two classes.\n",
    "    - Recall: 0.71 - Arithmetic mean of the recall of the two classes. Low due to extremely low recall for the ‘Top 20’ class.\n",
    "    - F1-Score: 0.73 - Arithmetic mean of the F1-Score of the two classes. Reflects the difficulty of the model in handling the ‘Top 20’ class.\n",
    "- **Weighted Average**.\n",
    "    - Precision: 0.87 - Weighted average of the precision, considering the support (size) of each class.\n",
    "    - Recall: 0.88 - Weighted average of recall, strongly influenced by the high recall of the ‘Non-Top 20’ class.\n",
    "    - F1-Score: 0.87 - Weighted average of the F1-Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute and visualize Confusion Matrix\n",
    "cm = confusion_matrix(y_test, test_pred_clf)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=rf.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to read the results:\n",
    "\n",
    "- True Negatives (TN): 28804 - Correct predictions for class 0.\n",
    "\n",
    "- False Positives (FP): 1662 - Incorrect predictions that indicated 1 instead of 0.\n",
    "\n",
    "- False Negatives (FN): 2594 - Incorrect predictions that indicated 0 instead of 1.\n",
    "\n",
    "- True Positives (TP): 2346 - Correct predictions for class 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naïve Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes is a probabilistic machine learning algorithm based on Bayes' theorem. \n",
    "\n",
    "The algorithm assumes that the features are independent of each other, a simplification that is rarely true in real-world scenarios but often works well in practice. Naive Bayes calculates the probability of a data point belonging to a particular class by considering the prior probability of the class and the likelihood of the features given the class. \n",
    "\n",
    "The \"naive\" assumption of feature independence allows the algorithm to be computationally efficient and easy to implement. \n",
    "\n",
    "Gaussian Naive Bayes, a common variant, assumes that the features follow a Gaussian (normal) distribution and is particularly suited for continuous data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naïve Bayes training\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(x_train, y_train)  \n",
    "\n",
    "#Prediction employing Naive Bayes\n",
    "test_pred_gnb = gnb.predict(x_test)  \n",
    "\n",
    "#Compute the performance of the model\n",
    "report_scores(y_test, test_pred_gnb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to read the result:\n",
    "- **Non-Top 20**: \n",
    "    - Precision: 0.88 - Of all the predictions that the model classified as ‘Non-Top 20’, 88% were correct.\n",
    "    - Recall: 0.88: 88% of the riders actually ‘Non-Top 20’ were correctly identified by the model.\n",
    "    - F1-Score: 0.88 - Represents the balance between precision and recall, and is very high for this class, indicating that the model is excellent at correctly distinguishing ‘Non-Top 20’ cyclists.\n",
    "    - Support: 30.466 - Indicates the total number of true samples belonging to the ‘Non-Top 20’ class.\n",
    "- **Top 20**: \n",
    "    - Precision: 0.24 - Of all predictions classified as ‘Top 20’, only 33% are correct. This indicates that the model tends to include false positives.\n",
    "    - Recall: 0.23 - 77% of the cyclists actually in the ‘Top 20’ were recognised correctly. \n",
    "    - F1-Score: 0.23 - Being the balance between precision and recall, the mid-low value suggests that the model has difficulty with the ‘Top 20’ class.\n",
    "    - Support: 4.940 - Indicates the total number of true samples belonging to the ‘Top 20’ class.\n",
    "- **Accuracy** \n",
    "    - Accuracy: 0.79 - Percentage of correct predictions out of the total data. Although the value is high, it is influenced by the strong dominance of the Non-Top 20 class (majority class).\n",
    "- **Macro Average**\n",
    "    - Precision: 0.56 - Arithmetic mean of the precision of the two classes.\n",
    "    - Recall: 0.56 - Arithmetic mean of the recall of the two classes. Low due to extremely low recall for the ‘Top 20’ class.\n",
    "    - F1-Score: 0.56 - Arithmetic mean of the F1-Score of the two classes. Reflects the difficulty of the model in handling the ‘Top 20’ class.\n",
    "- **Weighted Average**.\n",
    "    - Precision: 0.79 - Weighted average of the precision, considering the support (size) of each class.\n",
    "    - Recall: 0.79 - Weighted average of recall, strongly influenced by the high recall of the ‘Non-Top 20’ class.\n",
    "    - F1-Score: 0.79 - Weighted average of the F1-Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute and visualize Confusion Matrix\n",
    "cm = confusion_matrix(y_test, test_pred_gnb)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=dt.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to read the results:\n",
    "\n",
    "- True Negatives (TN): 26782 - Correct predictions for class 0.\n",
    "\n",
    "- False Positives (FP): 3684 - Incorrect predictions that indicated 1 instead of 0.\n",
    "\n",
    "- False Negatives (FN): 3795 - Incorrect predictions that indicated 0 instead of 1.\n",
    "\n",
    "- True Positives (TP): 1145 - Correct predictions for class 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_neighbors=3: Considera i 3 vicini più prossimi per classificare un nuovo campione.\n",
    "algorithm='ball_tree': Algoritmo che ottimizza la ricerca dei vicini più prossimi.\n",
    "metric='minkowski': Misura la distanza Euclidea tra campioni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definition of KNN model with 3 neighbours and ‘ball_tree’ algorithm\n",
    "knn = KNeighborsClassifier(n_neighbors=3, algorithm='ball_tree', metric='minkowski')\n",
    "\n",
    "#Train KNN on the training data\n",
    "knn.fit(x_train, y_train) \n",
    "\n",
    "#Prediction\n",
    "test_pred_knn = knn.predict(x_test)    # Predictions on the test set\n",
    "\n",
    "#Compute the performance of the model\n",
    "report_scores(y_test, test_pred_knn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to read the result:\n",
    "- **Non-Top 20**: \n",
    "    - Precision: 0.90 - Of all the predictions that the model classified as ‘Non-Top 20’, 90% were correct.\n",
    "    - Recall: 0.86: 86% of the riders actually ‘Non-Top 20’ were correctly identified by the model.\n",
    "    - F1-Score: 0.88 - Represents the balance between precision and recall, and is very high for this class, indicating that the model is excellent at correctly distinguishing ‘Non-Top 20’ cyclists.\n",
    "    - Support: 30.466 - Indicates the total number of true samples belonging to the ‘Non-Top 20’ class.\n",
    "- **Top 20**: \n",
    "    - Precision: 0.30 - Of all predictions classified as ‘Top 20’, only 63% are correct. This indicates that the model tends to include false positives.\n",
    "    - Recall: 0.38 - Only 38% of the cyclists actually in the ‘Top 20’ were recognised correctly. This indicates that the model is not effective in capturing true positives in this class.\n",
    "    - F1-Score: 0.34 - Being the balance between precision and recall, the low value suggests that the model has difficulty with the ‘Top 20’ class.\n",
    "    - Support: 4.940 - Indicates the total number of true samples belonging to the ‘Top 20’ class.\n",
    "- **Accuracy** \n",
    "    - Accuracy: 0.79 - Percentage of correct predictions out of the total data. Although the value is high, it is influenced by the strong dominance of the Non-Top 20 class (majority class).\n",
    "- **Macro Average**\n",
    "    - Precision: 0.60 - Arithmetic mean of the precision of the two classes.\n",
    "    - Recall: 0.62 - Arithmetic mean of the recall of the two classes. Low due to extremely low recall for the ‘Top 20’ class.\n",
    "    - F1-Score: 0.61 - Arithmetic mean of the F1-Score of the two classes. Reflects the difficulty of the model in handling the ‘Top 20’ class.\n",
    "- **Weighted Average**.\n",
    "    - Precision: 0.81 - Weighted average of the precision, considering the support (size) of each class.\n",
    "    - Recall: 0.79 - Weighted average of recall, strongly influenced by the high recall of the ‘Non-Top 20’ class.\n",
    "    - F1-Score: 0.80 - Weighted average of the F1-Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute and visualize Confusion Matrix\n",
    "cm = confusion_matrix(y_test, test_pred_knn)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=dt.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to read the results:\n",
    "\n",
    "- True Negatives (TN): 26211 - Correct predictions for class 0.\n",
    "\n",
    "- False Positives (FP): 4255 - Incorrect predictions that indicated 1 instead of 0.\n",
    "\n",
    "- False Negatives (FN): 3075 - Incorrect predictions that indicated 0 instead of 1.\n",
    "\n",
    "- True Positives (TP): 1865 - Correct predictions for class 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to NumPy arrays\n",
    "y_train = np.asarray(y_train).astype('float32').reshape((-1, 1))  # Convert training labels to NumPy arrays\n",
    "y_test = np.asarray(y_test).astype('float32').reshape((-1, 1))    # Convert test labels to NumPy arrays\n",
    "\n",
    "# Define the neural network model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(x_train.shape[1],)),  # Input layer\n",
    "    tf.keras.layers.Dropout(0.2),  # Dropout to prevent overfitting\n",
    "    tf.keras.layers.Dense(128, activation='relu'),  # Hidden layer\n",
    "    tf.keras.layers.Dropout(0.2),  # Dropout to improve generalization\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adamax',                       # Adam optimizer\n",
    "              loss='mean_squared_error',             # Binary cross-entropy for binary classification\n",
    "              metrics=['accuracy'])                   # Track accuracy during training and evaluation\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    x_train, y_train,                 # Training data\n",
    "    epochs=80,                        # Number of training epochs\n",
    "    batch_size=256,                    # Batch size\n",
    "    validation_split=0.2          # Verbose output for training progress\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation accuracy\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training Acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation Acc')\n",
    "plt.title('Training and validation Acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "test_pred_proba = model.predict(x_test)\n",
    "test_pred = (test_pred_proba > 0.5).astype('int32')\n",
    "\n",
    "#Compute the performance of the model\n",
    "report_scores(y_test, test_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to read the result:\n",
    "- **Non-Top 20**: \n",
    "    - Precision: 0.96 - Of all the predictions that the model classified as ‘Non-Top 20’, 96% were correct.\n",
    "    - Recall: 0.81: 81% of the riders actually ‘Non-Top 20’ were correctly identified by the model.\n",
    "    - F1-Score: 0.88 - Represents the balance between precision and recall, and is very high for this class, indicating that the model is excellent at correctly distinguishing ‘Non-Top 20’ cyclists.\n",
    "    - Support: 30.466 - Indicates the total number of true samples belonging to the ‘Non-Top 20’ class.\n",
    "- **Top 20**: \n",
    "    - Precision: 0.40 - Of all predictions classified as ‘Top 20’, only 40% are correct. This indicates that the model tends to include false positives.\n",
    "    - Recall: 0.79 - Only 79% of the cyclists actually in the ‘Top 20’ were recognised correctly. This indicates that the model is not effective in capturing true positives in this class.\n",
    "    - F1-Score: 0.53 - Being the balance between precision and recall, the low value suggests that the model has difficulty with the ‘Top 20’ class.\n",
    "    - Support: 4.940 - Indicates the total number of true samples belonging to the ‘Top 20’ class.\n",
    "- **Accuracy** \n",
    "    - Accuracy: 0.81 - Percentage of correct predictions out of the total data. Although the value is high, it is influenced by the strong dominance of the Non-Top 20 class (majority class).\n",
    "- **Macro Average**\n",
    "    - Precision: 0.68 - Arithmetic mean of the precision of the two classes.\n",
    "    - Recall: 0.80 - Arithmetic mean of the recall of the two classes. Low due to extremely low recall for the ‘Top 20’ class.\n",
    "    - F1-Score: 0.71 - Arithmetic mean of the F1-Score of the two classes. Reflects the difficulty of the model in handling the ‘Top 20’ class.\n",
    "- **Weighted Average**.\n",
    "    - Precision: 0.88 - Weighted average of the precision, considering the support (size) of each class.\n",
    "    - Recall: 0.81 - Weighted average of recall, strongly influenced by the high recall of the ‘Non-Top 20’ class.\n",
    "    - F1-Score: 0.83 - Weighted average of the F1-Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute and visualize Confusion Matrix\n",
    "cm = confusion_matrix(y_test, test_pred_proba)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=dt.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to read the results:\n",
    "\n",
    "- True Negatives (TN): 24684 - Correct predictions for class 0.\n",
    "\n",
    "- False Positives (FP): 5782 - Incorrect predictions that indicated 1 instead of 0.\n",
    "\n",
    "- False Negatives (FN): 1042 - Incorrect predictions that indicated 0 instead of 1.\n",
    "\n",
    "- True Positives (TP): 3898 - Correct predictions for class 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison between all models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **ROC curve**: Displays the relationship between the True Positive Rate and the False Positive Rate. A curve closer to the upper left corner indicates better performance.\n",
    "\n",
    "- **AUC (Area Under Curve)**: A higher AUC value indicates a better predictive ability of the model. The maximum value is 1 (perfect classifier), while 0.5 indicates a random model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(0).clf()  # Clear the current figure\n",
    "\n",
    "# Decision Tree\n",
    "fpr, tpr, thresh = metrics.roc_curve(y_test, test_pred_dt)\n",
    "auc = metrics.roc_auc_score(y_test, test_pred_dt)\n",
    "plt.plot(fpr, tpr, label=\"DecisionTree, auc=\" + str(round(auc, 3)))\n",
    "\n",
    "# Random Forest\n",
    "fpr, tpr, thresh = metrics.roc_curve(y_test, test_pred_rf)\n",
    "auc = metrics.roc_auc_score(y_test, test_pred_rf)\n",
    "plt.plot(fpr, tpr, label=\"RandomForest, auc=\" + str(round(auc, 3)))\n",
    "\n",
    "# AdaBoost\n",
    "fpr, tpr, thresh = metrics.roc_curve(y_test, test_pred_clf)\n",
    "auc = metrics.roc_auc_score(y_test, test_pred_clf)\n",
    "plt.plot(fpr,tpr,label=\"AdaBoost, auc=\"+str(auc))\n",
    "\n",
    "# Naive Bayes\n",
    "fpr, tpr, thresh = metrics.roc_curve(y_test, test_pred_gnb)\n",
    "auc = metrics.roc_auc_score(y_test, test_pred_gnb)\n",
    "plt.plot(fpr, tpr, label=\"Naive Bayes, auc=\" + str(round(auc, 3)))\n",
    "\n",
    "\n",
    "# K-Nearest Neighbor\n",
    "fpr, tpr, thresh = metrics.roc_curve(y_test, test_pred_knn)\n",
    "auc = metrics.roc_auc_score(y_test, test_pred_knn)\n",
    "plt.plot(fpr, tpr, label=\"KNN, auc=\" + str(round(auc, 3)))\n",
    "\n",
    "# Neural Network\n",
    "test_pred_nn = model.predict(x_test).ravel()  # Predict probabilities for Neural Network\n",
    "fpr, tpr, thresh = metrics.roc_curve(y_test, test_pred_nn)\n",
    "auc = metrics.roc_auc_score(y_test, test_pred_nn)\n",
    "plt.plot(fpr, tpr, label=\"Neural Network, auc=\" + str(round(auc, 3)))\n",
    "\n",
    "# Layout\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Comparison of ROC Curves')\n",
    "plt.legend(loc=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5: Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La feature importance misura il contributo di ciascuna variabile indipendente (feature) alla predizione del modello.\n",
    "\n",
    "Le feature con i valori più alti sono quelle che il modello considera più rilevanti per fare predizioni.\n",
    "Confronta le feature importanti con i pattern emersi durante la fase di esplorazione e clustering. Ad esempio:\n",
    "Le feature più importanti evidenziate dal modello corrispondono a quelle più significative emerse dal clustering?\n",
    "Ci sono nuove feature importanti che non erano evidenti in precedenza?\n",
    "\n",
    "La rule explanation implica la comprensione delle regole decisionali usate dal modello. È particolarmente utile per modelli basati su alberi decisionali (Decision Tree, Random Forest).\n",
    "Le regole decisionali del modello corrispondono ai pattern scoperti durante l'esplorazione dei dati?\n",
    "Sono comprensibili e coerenti con l'intuizione (esempio: gare con salite alte sono più difficili)?\n",
    "Ci sono regole inaspettate o poco intuitive?\n",
    "\n",
    "I counterfactual instances spiegano cosa sarebbe successo se alcune variabili fossero state modificate. Ti permettono di rispondere a domande del tipo: “Cosa sarebbe successo se il ciclista avesse avuto un peso inferiore o gareggiato in una stagione diversa?”\n",
    "I counterfactual instances rivelano la sensibilità del modello a diverse feature.\n",
    "Verifica se le modifiche richieste sono realistiche e sensate rispetto ai dati (esempio: un ciclista che deve migliorare drasticamente il tempo di scalata potrebbe non essere realistico).\n",
    "Confronta i counterfactuals con i pattern emersi nella fase di analisi iniziale.\n",
    "\n",
    "Analisi Comparativa\n",
    "Dopo aver completato le analisi sopra:\n",
    "\n",
    "Fidelity e Complessità:\n",
    "La feature importance, le regole decisionali e i counterfactuals sono coerenti con i dati di addestramento e i risultati del clustering?\n",
    "Sono comprensibili o eccessivamente complesse?\n",
    "Nuovi Pattern:\n",
    "Il modello ha evidenziato nuove relazioni tra le variabili (esempio: l’importanza della superficie tarmac o della stagione)?\n",
    "Pattern Inattesi:\n",
    "Ci sono risultati che non ti aspettavi? Ad esempio, una feature considerata importante dal modello non era stata identificata come rilevante durante l’esplorazione iniziale.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta                0.707846\n",
      "race_intensity       0.098949\n",
      "climb_total          0.077642\n",
      "date                 0.071769\n",
      "bmi                  0.020569\n",
      "startlist_quality    0.014791\n",
      "race_url             0.008434\n",
      "season               0.000000\n",
      "nationality          0.000000\n",
      "cyclist_url          0.000000\n",
      "is_tarmac            0.000000\n",
      "month                0.000000\n",
      "points               0.000000\n",
      "cyclist_age          0.000000\n",
      "profile              0.000000\n",
      "length               0.000000\n",
      "continent            0.000000\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Supponiamo di avere un Random Forest addestrato: dt\n",
    "feature_importance = pd.Series(dt.feature_importances_, index=x_train.columns)\n",
    "feature_importance = feature_importance.sort_values(ascending=False)\n",
    "\n",
    "# Visualizzazione\n",
    "feature_importance.plot(kind='bar', title=\"Feature Importance\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from datasets import load_dataset\n",
    "import pandas\n",
    "\n",
    "from transformations import center_and_scale, drop_boolean\n",
    "\n",
    "#noi abbiamo data_merged\n",
    "train_dataset = load_dataset(\"mstz/adult\", \"income\")[\"train\"].to_pandas()\n",
    "test_dataset = load_dataset(\"mstz/adult\", \"income\")[\"test\"].to_pandas()\n",
    "train_labels = train_dataset[\"over_threshold\"]\n",
    "test_labels = test_dataset[\"over_threshold\"]\n",
    "train_data = train_dataset.drop(\"over_threshold\", axis=\"columns\", inplace=False).select_dtypes(include=\"number\")\n",
    "test_data = test_dataset.drop(\"over_threshold\", axis=\"columns\", inplace=False).select_dtypes(include=\"number\")\n",
    "\n",
    "\n",
    "full_dataset = pandas.concat((train_data, test_data))\n",
    "_, normalization_scalers_dataset = center_and_scale(full_dataset)\n",
    "\n",
    "# apply normalization\n",
    "for feature, scaler in normalization_scalers_dataset.items():\n",
    "    train_data[feature] = scaler.transform(train_dataset[feature].values.reshape(-1, 1))\n",
    "    test_data[feature] = scaler.transform(test_dataset[feature].values.reshape(-1, 1))\n",
    "\n",
    "# model\n",
    "base_model = XGBClassifier()\n",
    "hyperparameters = {\n",
    "    \"n_estimators\": [25, 100, 250],\n",
    "    \"max_depth\": [2, 3],\n",
    "    \"learning_rate\": [1, 0.1, 0.001, 0.0001]\n",
    "}\n",
    "search = RandomizedSearchCV(base_model, hyperparameters, cv=5)\n",
    "search.fit(train_data, train_labels)\n",
    "model = search.best_estimator_\n",
    "train_labels_model = model.predict(train_data)\n",
    "test_labels_model = model.predict(test_data)\n",
    "\n",
    "validation = classification_report(test_labels, test_labels_model, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "interventional_explanation_algorithm = shap.TreeExplainer(\n",
    "    model=model,\n",
    "    data=train_data,                       # perturb on a causal model induced on perturbation data\n",
    "    feature_perturbation=\"interventional\"  # use a causal model\n",
    ")\n",
    "\n",
    "distributional_explanation_algorithm = shap.TreeExplainer(\n",
    "    model=model,\n",
    "    feature_perturbation=\"tree_path_dependent\"  # condition on the distribution learned on the train data\n",
    ")\n",
    "\n",
    "interventional_explanations = interventional_explanation_algorithm(explanation_data)\n",
    "distributional_explanations = distributional_explanation_algorithm(explanation_data)\n",
    "\n",
    "explanations[\"shap_interventional\"] = interventional_explanations.values\n",
    "explanations[\"shap_distributional\"] = distributional_explanations.values\n",
    "\n",
    "shap.plots.beeswarm(interventional_explanations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(distributional_explanations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rule explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(30, 20))\n",
    "plot_tree(dt, feature_names=x_train.columns, class_names=['Non-Top 20', 'Top 20'], filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_text\n",
    "# Stampare la rappresentazione testuale dell'albero\n",
    "tree_rules = export_text(dt, feature_names=list(x_train.columns))\n",
    "print(tree_rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counterfactual instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Copia dell'esempio e modifica della caratteristica 'climb_total'\n",
    "modified_example = x_test.iloc[0].copy()\n",
    "modified_example['climb_total'] += 500  # Aggiungi 500 metri di salita\n",
    "\n",
    "# Fare in modo che l'input abbia la forma corretta per il modello\n",
    "modified_example = np.array(modified_example).reshape(1, -1)  # Reshape per avere la forma (1, 17)\n",
    "\n",
    "# Predizione con l'esempio modificato\n",
    "modified_pred = model.predict(modified_example)\n",
    "print(f\"Predizione modificata: {modified_pred}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
