{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourth Task: Prediction\n",
    "\n",
    "We begin, as always, by importing all the necessary libraries and loading the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import warnings\n",
    "#import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import scipy.stats as stats\n",
    "#import seaborn as sns\n",
    "#import unidecode\n",
    "\n",
    "#from collections import defaultdict\n",
    "\n",
    "#from scipy.stats import pearsonr, mode\n",
    "#from scipy.spatial.distance import pdist, squareform\n",
    "#from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "import pydotplus \n",
    "from IPython.display import Image  \n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import wittgenstein as lw\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#import os\n",
    "\n",
    "cyclists = pd.read_csv('./dataset/cyclists_trasformed.csv')\n",
    "races = pd.read_csv('./dataset/races_trasformed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the specification we consider only the races from 2022 onward and we consider only top-20 placement to defining the learning task as a binary classification task: one class indicating top placement, the other vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 589865 entries, 0 to 589864\n",
      "Data columns (total 17 columns):\n",
      " #   Column             Non-Null Count   Dtype         \n",
      "---  ------             --------------   -----         \n",
      " 0   _url               589865 non-null  object        \n",
      " 1   name               589865 non-null  object        \n",
      " 2   points             589865 non-null  int64         \n",
      " 3   length             589865 non-null  float64       \n",
      " 4   climb_total        589865 non-null  int64         \n",
      " 5   profile            589865 non-null  int64         \n",
      " 6   startlist_quality  589865 non-null  int64         \n",
      " 7   date               589865 non-null  datetime64[ns]\n",
      " 8   position           589865 non-null  int64         \n",
      " 9   cyclist            589865 non-null  object        \n",
      " 10  cyclist_age        589865 non-null  int64         \n",
      " 11  is_tarmac          589865 non-null  bool          \n",
      " 12  cyclist_team       589865 non-null  object        \n",
      " 13  delta              589865 non-null  float64       \n",
      " 14  month              589865 non-null  int64         \n",
      " 15  season             589865 non-null  object        \n",
      " 16  race_intensity     589865 non-null  float64       \n",
      "dtypes: bool(1), datetime64[ns](1), float64(3), int64(7), object(5)\n",
      "memory usage: 72.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Ensure the 'date' column is in datetime format\n",
    "races['date'] = pd.to_datetime(races['date'])\n",
    "races.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before employing the learning algorithms to fit a prediction model for the given purpose (= predict the final position in a race for a given cyclist), we need to perform a few adjustments to our data. \n",
    "Firstly, it is necessary to merge the two dataset since we need features from both tables in our learning algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       _url_x name_x  points  length  climb_total  profile  startlist_quality  \\\n",
      "53046     NaN    NaN     NaN     NaN          NaN      NaN                NaN   \n",
      "56942     NaN    NaN     NaN     NaN          NaN      NaN                NaN   \n",
      "61189     NaN    NaN     NaN     NaN          NaN      NaN                NaN   \n",
      "89300     NaN    NaN     NaN     NaN          NaN      NaN                NaN   \n",
      "94337     NaN    NaN     NaN     NaN          NaN      NaN                NaN   \n",
      "139563    NaN    NaN     NaN     NaN          NaN      NaN                NaN   \n",
      "142896    NaN    NaN     NaN     NaN          NaN      NaN                NaN   \n",
      "154121    NaN    NaN     NaN     NaN          NaN      NaN                NaN   \n",
      "171916    NaN    NaN     NaN     NaN          NaN      NaN                NaN   \n",
      "180790    NaN    NaN     NaN     NaN          NaN      NaN                NaN   \n",
      "197846    NaN    NaN     NaN     NaN          NaN      NaN                NaN   \n",
      "200906    NaN    NaN     NaN     NaN          NaN      NaN                NaN   \n",
      "205189    NaN    NaN     NaN     NaN          NaN      NaN                NaN   \n",
      "225951    NaN    NaN     NaN     NaN          NaN      NaN                NaN   \n",
      "257826    NaN    NaN     NaN     NaN          NaN      NaN                NaN   \n",
      "259180    NaN    NaN     NaN     NaN          NaN      NaN                NaN   \n",
      "314792    NaN    NaN     NaN     NaN          NaN      NaN                NaN   \n",
      "317916    NaN    NaN     NaN     NaN          NaN      NaN                NaN   \n",
      "326819    NaN    NaN     NaN     NaN          NaN      NaN                NaN   \n",
      "334444    NaN    NaN     NaN     NaN          NaN      NaN                NaN   \n",
      "350764    NaN    NaN     NaN     NaN          NaN      NaN                NaN   \n",
      "372074    NaN    NaN     NaN     NaN          NaN      NaN                NaN   \n",
      "380687    NaN    NaN     NaN     NaN          NaN      NaN                NaN   \n",
      "386955    NaN    NaN     NaN     NaN          NaN      NaN                NaN   \n",
      "387281    NaN    NaN     NaN     NaN          NaN      NaN                NaN   \n",
      "414960    NaN    NaN     NaN     NaN          NaN      NaN                NaN   \n",
      "423862    NaN    NaN     NaN     NaN          NaN      NaN                NaN   \n",
      "429134    NaN    NaN     NaN     NaN          NaN      NaN                NaN   \n",
      "430981    NaN    NaN     NaN     NaN          NaN      NaN                NaN   \n",
      "440591    NaN    NaN     NaN     NaN          NaN      NaN                NaN   \n",
      "454431    NaN    NaN     NaN     NaN          NaN      NaN                NaN   \n",
      "457373    NaN    NaN     NaN     NaN          NaN      NaN                NaN   \n",
      "469416    NaN    NaN     NaN     NaN          NaN      NaN                NaN   \n",
      "478817    NaN    NaN     NaN     NaN          NaN      NaN                NaN   \n",
      "479350    NaN    NaN     NaN     NaN          NaN      NaN                NaN   \n",
      "491991    NaN    NaN     NaN     NaN          NaN      NaN                NaN   \n",
      "516445    NaN    NaN     NaN     NaN          NaN      NaN                NaN   \n",
      "520410    NaN    NaN     NaN     NaN          NaN      NaN                NaN   \n",
      "543475    NaN    NaN     NaN     NaN          NaN      NaN                NaN   \n",
      "\n",
      "       date  position cyclist  ...                  name_y birth_year weight  \\\n",
      "53046   NaT       NaN     NaN  ...         Arturo Gravalos     1998.0   72.0   \n",
      "56942   NaT       NaN     NaN  ...             Bas Tietema     1995.0   74.0   \n",
      "61189   NaT       NaN     NaN  ...        Benjamin Levecot     1977.0   69.0   \n",
      "89300   NaT       NaN     NaN  ...         Christian Mager     1992.0   60.0   \n",
      "94337   NaT       NaN     NaN  ...      Christophe Premont     1989.0   69.0   \n",
      "139563  NaT       NaN     NaN  ...        Dorian De Maeght     1997.0   79.0   \n",
      "142896  NaT       NaN     NaN  ...          Eddy Torrekens     1970.0   69.0   \n",
      "154121  NaT       NaN     NaN  ...            Eric Schoefs     1967.0   69.0   \n",
      "171916  NaT       NaN     NaN  ...   Flavio Cardoso Santos     1980.0   69.0   \n",
      "180790  NaT       NaN     NaN  ...          Franck Morelle     1964.0   69.0   \n",
      "197846  NaT       NaN     NaN  ...        Gert Van Brabant     1968.0   69.0   \n",
      "200906  NaT       NaN     NaN  ...       Gianluca Maggiore     1985.0   69.0   \n",
      "205189  NaT       NaN     NaN  ...              Gino Primo     1966.0   69.0   \n",
      "225951  NaT       NaN     NaN  ...        Hiroki Nishimura     1994.0   59.0   \n",
      "257826  NaT       NaN     NaN  ...     Jean-Michel Thilloy     1966.0   69.0   \n",
      "259180  NaT       NaN     NaN  ...     Jeanot Deriemaecker     1971.0   69.0   \n",
      "314792  NaT       NaN     NaN  ...     Koen Van Hullebusch     1970.0   69.0   \n",
      "317916  NaT       NaN     NaN  ...      Kurt van Landeghem     1972.0   69.0   \n",
      "326819  NaT       NaN     NaN  ...          Lenaic Olivier     1977.0   69.0   \n",
      "334444  NaT       NaN     NaN  ...            Luca Braidot     1991.0   69.0   \n",
      "350764  NaT       NaN     NaN  ...            Marat Ganeev     1964.0   69.0   \n",
      "372074  NaT       NaN     NaN  ...          Martin Gilbert     1982.0   73.0   \n",
      "380687  NaT       NaN     NaN  ...      Matteo Di Serafino     1986.0   69.0   \n",
      "386955  NaT       NaN     NaN  ...       Mattia Bevilacqua     1998.0   69.0   \n",
      "387281  NaT       NaN     NaN  ...             Mattia Viel     1995.0   72.0   \n",
      "414960  NaT       NaN     NaN  ...        Morten Hegreberg     1977.0   72.0   \n",
      "423862  NaT       NaN     NaN  ...        Nicolas Liboreau     1977.0   69.0   \n",
      "429134  NaT       NaN     NaN  ...          Oleg Grishkine     1975.0   69.0   \n",
      "430981  NaT       NaN     NaN  ...         Olivier Matthys     1971.0   69.0   \n",
      "440591  NaT       NaN     NaN  ...             Pascal Duez     1968.0   69.0   \n",
      "454431  NaT       NaN     NaN  ...        Peter Spaenhoven     1963.0   69.0   \n",
      "457373  NaT       NaN     NaN  ...       Philipp Ludescher     1987.0   72.0   \n",
      "469416  NaT       NaN     NaN  ...           Raphael Pires     1997.0   63.0   \n",
      "478817  NaT       NaN     NaN  ...              Rik Claeys     1967.0   69.0   \n",
      "479350  NaT       NaN     NaN  ...     Rikkie Matthijssens     1972.0   69.0   \n",
      "491991  NaT       NaN     NaN  ...            Roman Bronis     1976.0   74.0   \n",
      "516445  NaT       NaN     NaN  ...  Sergio Garcia Gonzalez     1999.0   62.0   \n",
      "520410  NaT       NaN     NaN  ...       Silvere Ackermann     1984.0   62.0   \n",
      "543475  NaT       NaN     NaN  ...             Tanner Putt     1992.0   75.0   \n",
      "\n",
      "        height    nationality        bmi      continent avg_position  \\\n",
      "53046    185.0          Spain  21.037253         Europe           78   \n",
      "56942    185.0    Netherlands  21.621622         Europe           78   \n",
      "61189    180.0         France  21.296296         Europe           78   \n",
      "89300    172.0        Germany  20.281233         Europe           78   \n",
      "94337    178.0        Belgium  21.777553         Europe           78   \n",
      "139563   181.0        Belgium  24.114038         Europe           78   \n",
      "142896   180.0        Belgium  21.296296         Europe           78   \n",
      "154121   180.0        Belgium  21.296296         Europe           78   \n",
      "171916   180.0         Brazil  21.296296  South America           78   \n",
      "180790   180.0         France  21.296296         Europe           78   \n",
      "197846   180.0        Belgium  21.296296         Europe           78   \n",
      "200906   180.0          Italy  21.296296         Europe           78   \n",
      "205189   180.0        Belgium  21.296296         Europe           78   \n",
      "225951   172.0          Japan  19.943213           Asia           78   \n",
      "257826   180.0         France  21.296296         Europe           78   \n",
      "259180   180.0        Belgium  21.296296         Europe           78   \n",
      "314792   180.0        Belgium  21.296296         Europe           78   \n",
      "317916   180.0        Belgium  21.296296         Europe           78   \n",
      "326819   180.0         France  21.296296         Europe           78   \n",
      "334444   179.0          Italy  21.534908         Europe           78   \n",
      "350764   180.0         Russia  21.296296           Asia           78   \n",
      "372074   177.0         Canada  23.301095  North America           78   \n",
      "380687   180.0          Italy  21.296296         Europe           78   \n",
      "386955   180.0          Italy  21.296296         Europe           78   \n",
      "387281   180.0          Italy  22.222222         Europe           78   \n",
      "414960   180.0         Norway  22.222222         Europe           78   \n",
      "423862   180.0         France  21.296296         Europe           78   \n",
      "429134   180.0         Russia  21.296296           Asia           78   \n",
      "430981   180.0        Belgium  21.296296         Europe           78   \n",
      "440591   180.0        Belgium  21.296296         Europe           78   \n",
      "454431   180.0        Belgium  21.296296         Europe           78   \n",
      "457373   187.0        Austria  20.589665         Europe           78   \n",
      "469416   178.0         Brazil  19.883853  South America           78   \n",
      "478817   180.0        Belgium  21.296296         Europe           78   \n",
      "479350   180.0        Belgium  21.296296         Europe           78   \n",
      "491991   187.0       Slovakia  21.161600         Europe           78   \n",
      "516445   183.0          Spain  18.513542         Europe           78   \n",
      "520410   182.0    Switzerland  18.717546         Europe           78   \n",
      "543475   178.0  United States  23.671254  North America           78   \n",
      "\n",
      "         avg_delta      _merge  \n",
      "53046   426.851259  right_only  \n",
      "56942   426.851259  right_only  \n",
      "61189   426.851259  right_only  \n",
      "89300   426.851259  right_only  \n",
      "94337   426.851259  right_only  \n",
      "139563  426.851259  right_only  \n",
      "142896  426.851259  right_only  \n",
      "154121  426.851259  right_only  \n",
      "171916  426.851259  right_only  \n",
      "180790  426.851259  right_only  \n",
      "197846  426.851259  right_only  \n",
      "200906  426.851259  right_only  \n",
      "205189  426.851259  right_only  \n",
      "225951  426.851259  right_only  \n",
      "257826  426.851259  right_only  \n",
      "259180  426.851259  right_only  \n",
      "314792  426.851259  right_only  \n",
      "317916  426.851259  right_only  \n",
      "326819  426.851259  right_only  \n",
      "334444  426.851259  right_only  \n",
      "350764  426.851259  right_only  \n",
      "372074  426.851259  right_only  \n",
      "380687  426.851259  right_only  \n",
      "386955  426.851259  right_only  \n",
      "387281  426.851259  right_only  \n",
      "414960  426.851259  right_only  \n",
      "423862  426.851259  right_only  \n",
      "429134  426.851259  right_only  \n",
      "430981  426.851259  right_only  \n",
      "440591  426.851259  right_only  \n",
      "454431  426.851259  right_only  \n",
      "457373  426.851259  right_only  \n",
      "469416  426.851259  right_only  \n",
      "478817  426.851259  right_only  \n",
      "479350  426.851259  right_only  \n",
      "491991  426.851259  right_only  \n",
      "516445  426.851259  right_only  \n",
      "520410  426.851259  right_only  \n",
      "543475  426.851259  right_only  \n",
      "\n",
      "[39 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "#TODO: DECIDERE DEI AVG POS E AVG DELTA DI CHI NON HA MAI GAREGGIATO \n",
    "\n",
    "# Merge con indicator=True\n",
    "data_merged = pd.merge(races, cyclists, left_on='cyclist', right_on='_url', how='outer', indicator=True)\n",
    "\n",
    "# Filtra le entries che non corrispondono\n",
    "mismatched = data_merged[data_merged['_merge'] != 'both']\n",
    "\n",
    "#print(\"\\nMismatched entries:\")\n",
    "print(mismatched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thereafter, we can reduce the size of our table by deleting the columns not useful for the purpose and adding one for specifying if a certain cyclist was in the first 20 position of a race or not. \n",
    "\n",
    "We deleted:\n",
    "\n",
    "•*_url* (coming from cyclist) and *name* from (coming from races), since it is a repetition for *cyclist* in cyclist\n",
    "\n",
    "• *weight* and *height* (coming from cyclist), since these characteristics are combined in the *bmi* feature we created \n",
    "\n",
    "• *nationality* (coming from cyclist), since it would be impractical to handle for its size (we left instead *continent*)\n",
    "\n",
    "• *avg_position* and *avg_delta* (coming from cyclist), since it is better to consider more precise columns like *position* (see next) and *delta* from races\n",
    "\n",
    "• *position* (coming from races) since we consider only the first 20 we will get from the new column \n",
    "\n",
    "• *birth_year* (coming from cyclist) because it's redundant having *cyclist_age* from races\n",
    "\n",
    "• *cyclist_team* (coming from races) since we consider single cyclists\n",
    "\n",
    "• *date* (coming from races) whose format is: \"YYYY-MM-DD HH-MM-SS\". From it, we can extract the information we need: we exclude the \"HH-MM-SS\" and the \"MM-DD\" part because we can easily group races based on the *season* of the year (attribute that we already have). At the end, we only care about the year for splitting the races for the training set.\n",
    "\n",
    "We added:\n",
    "\n",
    "• *top_20*, having value =1 if the corresponding cyclist was in between these positions or, on the opposite, =0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   points    length  climb_total  profile  startlist_quality  \\\n",
      "0   100.0  162000.0       1101.0      1.0             1241.0   \n",
      "1   100.0   52000.0       1351.0      5.0             1241.0   \n",
      "2    50.0   30000.0         -1.0     -1.0              388.0   \n",
      "3   100.0  254000.0       3500.0      1.0             1362.0   \n",
      "4   100.0  231000.0       4000.0      4.0             1362.0   \n",
      "\n",
      "                 date  position           cyclist  cyclist_age is_tarmac  ...  \\\n",
      "0 1978-07-05 04:02:51      84.0  aad-van-den-hoek         27.0      True  ...   \n",
      "1 1978-07-14 01:39:34      83.0  aad-van-den-hoek         27.0      True  ...   \n",
      "2 1981-09-05 00:44:24       0.0  aad-van-den-hoek         30.0      True  ...   \n",
      "3 1981-06-27 06:36:45     133.0  aad-van-den-hoek         30.0      True  ...   \n",
      "4 1981-07-11 05:57:21      94.0  aad-van-den-hoek         30.0      True  ...   \n",
      "\n",
      "   delta  month  season race_intensity            _url_y            name_y  \\\n",
      "0   27.0    7.0  summer       1.503613  aad-van-den-hoek  Aad van den Hoek   \n",
      "1  823.0    7.0  summer       2.601488  aad-van-den-hoek  Aad van den Hoek   \n",
      "2    0.0    9.0  autumn       0.730875  aad-van-den-hoek  Aad van den Hoek   \n",
      "3  258.0    6.0  summer       1.552777  aad-van-den-hoek  Aad van den Hoek   \n",
      "4  614.0    7.0  summer       2.445407  aad-van-den-hoek  Aad van den Hoek   \n",
      "\n",
      "  birth_year        bmi  continent _merge  \n",
      "0     1951.0  22.256908     Europe   both  \n",
      "1     1951.0  22.256908     Europe   both  \n",
      "2     1951.0  22.256908     Europe   both  \n",
      "3     1951.0  22.256908     Europe   both  \n",
      "4     1951.0  22.256908     Europe   both  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "#Delete useless columns we cited\n",
    "data_merged = data_merged.drop(columns=['_url_x', 'name_x', '_url_y', 'name_y', 'weight', 'height', 'birth_year', 'nationality', 'avg_position', 'avg_delta', 'cyclist_team'])\n",
    "print(data_merged.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we ensure data is in a suitable form for learning algorithms, in order to do so we have to normalize them and encode categorical data into numerical one. \n",
    "The begin with continous numeric attributes (*points*, *length*, *climb_total*, *startlist_quality*, *delta*, *race_intensity*, *bmi*) with the Z-score normalization, whose formula is z = (x - media) / standard_deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-score normalization for points\n",
    "data_merged['points'] = (data_merged['points'] - data_merged['points'].mean()) / data_merged['points'].std()\n",
    "\n",
    "# Z-score normalization for length\n",
    "data_merged['length'] = (data_merged['length'] - data_merged['length'].mean()) / data_merged['length'].std()\n",
    "\n",
    "# Z-score normalization for climb_total\n",
    "data_merged['climb_total'] = (data_merged['climb_total'] - data_merged['climb_total'].mean()) / data_merged['climb_total'].std()\n",
    "\n",
    "# Z-score normalization for startlist_quality\n",
    "data_merged['startlist_quality'] = (data_merged['startlist_quality'] - data_merged['startlist_quality'].mean()) / data_merged['startlist_quality'].std()\n",
    "\n",
    "# Z-score normalization for delta\n",
    "data_merged['delta'] = (data_merged['delta'] - data_merged['delta'].mean()) / data_merged['delta'].std()\n",
    "\n",
    "# Z-score normalization for race_intensity\n",
    "data_merged['race_intensity'] = (data_merged['race_intensity'] - data_merged['race_intensity'].mean()) / data_merged['race_intensity'].std()\n",
    "\n",
    "# Z-score normalization for bmi\n",
    "data_merged['bmi'] = (data_merged['bmi'] - data_merged['bmi'].mean()) / data_merged['bmi'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we normalize *profile*, *season*, *month* since their increasing values have a specific meaning. \n",
    "\n",
    "To do so, we employ **Min-Max Scaling Method**, which formula is x_scaled = (x - min(x)) / (max(x) - min(x)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create instance for scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#Columns to which apply scaler\n",
    "columns_to_scale = ['profile', 'month', 'season']\n",
    "\n",
    "#Apply scaling and sobstitute values\n",
    "data_merged[columns_to_scale] = scaler.fit_transform(data_merged[columns_to_scale])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we deal with the temporal attribute *date* and extrapolate only the year part. \n",
    "\n",
    "TWe posticipate its normalization since we need the raw information to divide our dataset for the train set; if we normalize now, it is difficult to derive the normalized value for '2022'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extrapolate only YY\n",
    "data_merged['date'] = data_merged['date'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To end, we need to transform categorical value into numerical ones. \n",
    "\n",
    "We mapped every *continent* to a number and transformed the boolean *is_tarmac* in 0/1 values. \n",
    "For what concerns *cyclist*, we use the **Target Encoding**: each cyclist is represented by a number reflecting his average probability of a top 20 placement (performance-based encoding).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Continent\n",
    "#Extract unique 'continent'\n",
    "unique_continents = data_merged['continent'].unique()\n",
    "\n",
    "#Create mapping for each\n",
    "continent_map = {continent: idx for idx, continent in enumerate(unique_continents, start=1)}\n",
    "\n",
    "#Sobstitute values in the column\n",
    "data_merged['continent'] = data_merged['continent'].map(continent_map)\n",
    "\n",
    "#Is_tarmac\n",
    "#Transform boolean in 0/1 value\n",
    "data_merged['is_tarmac'] = data_merged['is_tarmac'].astype(int)\n",
    "\n",
    "#Cyclist\n",
    "#Calculate the average of the binary values ‘top_20’ for each cyclist\n",
    "cyclist_mean_top20 = data_merged.groupby('cyclist')['top_20'].mean().to_dict()\n",
    "\n",
    "#Replace in the ‘cyclist’ column in the dataset using the dictionary obtained\n",
    "data_merged['cyclist'] = data_merged['cyclist'].map(cyclist_mean_top20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To proceed, we divide the dataset in two parts: the races before 2022 (for training/validation set) and the races after 2022 (for the test set) and accurately define the binary classification: 1 for top-20 placement, 0 otherwise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Validation set:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 554459 entries, 0 to 589864\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   name               554459 non-null  object \n",
      " 1   points             554459 non-null  int64  \n",
      " 2   length             554459 non-null  float64\n",
      " 3   climb_total        554459 non-null  int64  \n",
      " 4   profile            554459 non-null  int64  \n",
      " 5   startlist_quality  554459 non-null  int64  \n",
      " 6   cyclist_age        554459 non-null  int64  \n",
      " 7   is_tarmac          554459 non-null  bool   \n",
      " 8   delta              554459 non-null  float64\n",
      " 9   month              554459 non-null  int64  \n",
      " 10  season             554459 non-null  object \n",
      " 11  race_intensity     554459 non-null  float64\n",
      " 12  top_20             554459 non-null  int64  \n",
      "dtypes: bool(1), float64(3), int64(7), object(2)\n",
      "memory usage: 55.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Filter the dataset into training/validation and test sets\n",
    "train_val_set = races[races['date'] < pd.Timestamp('2022')].copy() #Training/Validation Set\n",
    "test_set = races[races['date'] >= pd.Timestamp('2022')].copy() #Test set\n",
    "\n",
    "#Define the binary classification label: 1 for top-20 placement, 0 otherwise\n",
    "train_val_set['top_20'] = (train_val_set['position'] <= 20).astype(int)\n",
    "test_set['top_20'] = (test_set['position'] <= 20).astype(int)\n",
    "\n",
    "#Print the resulting datasets for verification\n",
    "print(\"Training/Validation set:\")\n",
    "print(train_val_set.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set:\n",
      "               name  points    length  climb_total  profile  \\\n",
      "545  Tour de France     100  192900.0         3743        3   \n",
      "546  Tour de France     100  192900.0         3743        3   \n",
      "547  Tour de France     100  192900.0         3743        3   \n",
      "548  Tour de France     100  192900.0         3743        3   \n",
      "549  Tour de France     100  192900.0         3743        3   \n",
      "\n",
      "     startlist_quality  cyclist_age  is_tarmac  delta  month  season  \\\n",
      "545               1551           30       True    0.0      7  summer   \n",
      "546               1551           35       True   22.0      7  summer   \n",
      "547               1551           30       True   26.0      7  summer   \n",
      "548               1551           32       True   40.0      7  summer   \n",
      "549               1551           24       True   49.0      7  summer   \n",
      "\n",
      "     race_intensity  top_20  \n",
      "545        2.128635       1  \n",
      "546        2.128635       1  \n",
      "547        2.128635       1  \n",
      "548        2.128635       1  \n",
      "549        2.128635       1  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTest set:\")\n",
    "print(test_set.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude this section with *date* normalization, as previously promised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization for 'date'\n",
    "data_merged['date'] = (data_merged['date'] - data_merged['date'].min()) / (data_merged['date'].max() - data_merged['date'].min())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models we choose can be divided in different categories:\n",
    "\n",
    "1) Tree-Based Models (Decision Tree, Random Forest, Gradient Boosting)\n",
    "\n",
    "2) Support Vector Machines (SVM)\n",
    "\n",
    "3) Naïve Bayes\n",
    "\n",
    "4) K-Nearest Neighbors (KNN)\n",
    "\n",
    "5) Neural Network\n",
    "\n",
    "6) Rule-based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree-Based Models (Decision Tree, Random Forest, Gradient Boosting)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before computing the DT, we create a validation set to evaluate the model during training without using the test set; *train_val_set* contains only the (independent) features, while *train_val_label* contains the target binary values (=*top_20*).\n",
    "\n",
    "The following code, divides the train_val_set into two sets:\n",
    "- *train_set*: For training the model.\n",
    "- *val_set*: To validate the model during tuning.\n",
    "\n",
    "It also divides the train_val_label into:\n",
    "- *train_label*: Target for training.\n",
    "- *val_label*: Target for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate the target (top_20) from the dataset\n",
    "train_val_label = train_val_set.pop('top_20') #Contains the top_20 values for the training/validation set.\n",
    "test_label = test_set.pop('top_20') #Contains the top_20 values for the test set.\n",
    "\n",
    "#Split train_val_set into training and validation set\n",
    "train_set, val_set, train_label, val_label = train_test_split(\n",
    "    train_val_set, \n",
    "    train_val_label, \n",
    "    stratify=train_val_label, \n",
    "    test_size=0.30, #30% of the original training set is allocated for validation; 70% for training\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model creation and training is obtained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Volta a Catalunya'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 14\u001b[0m\n\u001b[1;32m      4\u001b[0m dt \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mDecisionTreeClassifier(\n\u001b[1;32m      5\u001b[0m     criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgini\u001b[39m\u001b[38;5;124m'\u001b[39m,               \u001b[38;5;66;03m#Use the Gini index to evaluate the purity of splits\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     splitter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest\u001b[39m\u001b[38;5;124m'\u001b[39m,                \u001b[38;5;66;03m#Splits the nodes by choosing the best split\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m                 \u001b[38;5;66;03m#Ensures repeatability of results\u001b[39;00m\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#Train the model\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m dt \u001b[38;5;241m=\u001b[39m \u001b[43mdt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_label\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Unipi/Esami/DATAMINING/dm_project24_group_4/env/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Unipi/Esami/DATAMINING/dm_project24_group_4/env/lib/python3.12/site-packages/sklearn/tree/_classes.py:1009\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    979\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    980\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    981\u001b[0m \n\u001b[1;32m    982\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1009\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1015\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/Unipi/Esami/DATAMINING/dm_project24_group_4/env/lib/python3.12/site-packages/sklearn/tree/_classes.py:252\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    248\u001b[0m check_X_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    249\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mDTYPE, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    250\u001b[0m )\n\u001b[1;32m    251\u001b[0m check_y_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 252\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_separately\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcheck_X_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_y_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m missing_values_in_feature_mask \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_missing_values_in_feature_mask(X)\n\u001b[1;32m    258\u001b[0m )\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n",
      "File \u001b[0;32m~/Desktop/Unipi/Esami/DATAMINING/dm_project24_group_4/env/lib/python3.12/site-packages/sklearn/base.py:645\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m check_X_params:\n\u001b[1;32m    644\u001b[0m     check_X_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdefault_check_params, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_X_params}\n\u001b[0;32m--> 645\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_X_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m check_y_params:\n\u001b[1;32m    647\u001b[0m     check_y_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdefault_check_params, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params}\n",
      "File \u001b[0;32m~/Desktop/Unipi/Esami/DATAMINING/dm_project24_group_4/env/lib/python3.12/site-packages/sklearn/utils/validation.py:929\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pandas_requires_conversion:\n\u001b[1;32m    925\u001b[0m     \u001b[38;5;66;03m# pandas dataframe requires conversion earlier to handle extension dtypes with\u001b[39;00m\n\u001b[1;32m    926\u001b[0m     \u001b[38;5;66;03m# nans\u001b[39;00m\n\u001b[1;32m    927\u001b[0m     \u001b[38;5;66;03m# Use the original dtype for conversion if dtype is None\u001b[39;00m\n\u001b[1;32m    928\u001b[0m     new_dtype \u001b[38;5;241m=\u001b[39m dtype_orig \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m dtype\n\u001b[0;32m--> 929\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;66;03m# Since we converted here, we do not need to convert again later\u001b[39;00m\n\u001b[1;32m    931\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Unipi/Esami/DATAMINING/dm_project24_group_4/env/lib/python3.12/site-packages/pandas/core/generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   6639\u001b[0m     ]\n\u001b[1;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Unipi/Esami/DATAMINING/dm_project24_group_4/env/lib/python3.12/site-packages/pandas/core/internals/managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Unipi/Esami/DATAMINING/dm_project24_group_4/env/lib/python3.12/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/Desktop/Unipi/Esami/DATAMINING/dm_project24_group_4/env/lib/python3.12/site-packages/pandas/core/internals/blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Unipi/Esami/DATAMINING/dm_project24_group_4/env/lib/python3.12/site-packages/pandas/core/dtypes/astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/Unipi/Esami/DATAMINING/dm_project24_group_4/env/lib/python3.12/site-packages/pandas/core/dtypes/astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/Desktop/Unipi/Esami/DATAMINING/dm_project24_group_4/env/lib/python3.12/site-packages/pandas/core/dtypes/astype.py:133\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Volta a Catalunya'"
     ]
    }
   ],
   "source": [
    "#Creating and configuring the Decision Tree\n",
    "dt = tree.DecisionTreeClassifier(\n",
    "    criterion='gini',               #Use the Gini index to evaluate the purity of splits\n",
    "    splitter='best',                #Splits the nodes by choosing the best split\n",
    "    max_depth=10,                   #Limit tree depth to 10 levels\n",
    "    min_samples_split=3,            #A node must have at least 3 samples to be split\n",
    "    min_samples_leaf=4,             #Each leaf must contain at least 4 examples\n",
    "    random_state=42                 #Ensures repeatability of results\n",
    ")\n",
    "\n",
    "#Train the model\n",
    "dt = dt.fit(train_set, train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the actual Decision Tree obtained: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To visualize the Decision Tree, you must intsall GraphViz\n",
    "#MacOs: brew install graphviz\n",
    "#Linux: sudo apt-get install graphviz\n",
    "#Windows: Install from here https://graphviz.org/download/ \n",
    "#and add the following enviroment variable (the path can change)\n",
    "#import os\n",
    "#os.environ[\"PATH\"] += os.pathsep + 'C:\\Program Files (x86)\\Graphviz2.38/bin/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(dt, out_file=None, \n",
    "                                feature_names=list(train_set.columns),  \n",
    "                                class_names=['Non-Top 20', 'Top 20'],  \n",
    "                                filled=True, rounded=True)  \n",
    "graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "Image(graph.create_png())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of the Decision Tree is done employing predictions, then we compute:\n",
    "\n",
    "• Accuracy (for both train and test set; percentage of correct predictions)\n",
    "\n",
    "• Precision (Percentage of correct predictions among all positive predictions)\n",
    "\n",
    "• Recall (Percentage of true positives identified)\n",
    "\n",
    "• F1 Score (Harmonic mean of precision and recall.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions: use the trained model to make predictions on the training and test datasets.\n",
    "train_pred_dt = dt.predict(train_set)\n",
    "test_pred_dt = dt.predict(test_set)\n",
    "\n",
    "#Evaluate metrics\n",
    "from sklearn import metrics\n",
    "print('Accuracy train set:', metrics.accuracy_score(train_label, train_pred_dt)) #Accuracy\n",
    "print('Accuracy test set:', metrics.accuracy_score(test_label, test_pred_dt)) #Accuracy\n",
    "print('Precision:', metrics.precision_score(test_label, test_pred_dt, average='weighted')) #Precision: Percentage of correct predictions among all positive predictions.\n",
    "print('Recall:', metrics.recall_score(test_label, test_pred_dt, average='weighted')) #Recall\n",
    "print('F1 Score:', metrics.f1_score(test_label, test_pred_dt, average='weighted')) #F1 Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute and visualize Confusion Matrix\n",
    "cm = confusion_matrix(test_label, test_pred_dt)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=dt.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatter plot\n",
    "plt.scatter(test_set.iloc[:, 1].values, test_set.iloc[:, 3].values, c=test_label.values, s=25, cmap='YlGn')\n",
    "plt.title(\"Scatter Plot of Test Set\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il Random Forest funziona combinando le predizioni di più alberi decisionali (Ensemble learning) per migliorare la robustezza e la precisione del modello.\n",
    "Perciò, impiega il Bagging (Bootstrap Aggregating), cioè l'utilizzo di sottoinsiemi casuali dei dati e delle feature per ogni albero, riducendo l'overfitting e l'Out-of-bag evaluation, una tecnica interna che valuta le prestazioni senza bisogno di un validation set separato.\n",
    "\n",
    "Costruzione degli Alberi:\n",
    "\n",
    "- Ogni albero è costruito usando un sottoinsieme casuale dei dati (con ripetizione, bootstrap).\n",
    "\n",
    "- Ad ogni split, considera un sottoinsieme casuale delle feature.\n",
    "\n",
    "Predizione:\n",
    "\n",
    "- Per la classificazione, aggrega le previsioni (voto a maggioranza).\n",
    "\n",
    "- Per la regressione, calcola la media delle predizioni degli alberi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomForestClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Random Forest definition and training\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m rf \u001b[38;5;241m=\u001b[39m \u001b[43mRandomForestClassifier\u001b[49m(\n\u001b[1;32m      3\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, \u001b[38;5;66;03m#Number of trees in the forest\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgini\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;66;03m#Measure to evaluate the purity of the split\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, \u001b[38;5;66;03m#Maximum number of features considered for each split\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, \u001b[38;5;66;03m#Maximum depth of trees\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     min_samples_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;66;03m#Minimum number of samples to split a node\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     min_samples_leaf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, \u001b[38;5;66;03m#Minimum number of samples in a leaf\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     bootstrap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;66;03m#Use bootstrap to create random subsets\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m \u001b[38;5;66;03m#Ensures repeatability of results\u001b[39;00m\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#Model training\u001b[39;00m\n\u001b[1;32m     14\u001b[0m rf \u001b[38;5;241m=\u001b[39m rf\u001b[38;5;241m.\u001b[39mfit(train_set, train_label)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RandomForestClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "#Random Forest definition and training\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=30, #Number of trees in the forest\n",
    "    criterion='gini', #Measure to evaluate the purity of the split\n",
    "    max_features=3, #Maximum number of features considered for each split\n",
    "    max_depth=4, #Maximum depth of trees\n",
    "    min_samples_split=2, #Minimum number of samples to split a node\n",
    "    min_samples_leaf=8, #Minimum number of samples in a leaf\n",
    "    bootstrap=True, #Use bootstrap to create random subsets\n",
    "    random_state=42 #Ensures repeatability of results\n",
    ")\n",
    "\n",
    "#Model training\n",
    "rf = rf.fit(train_set, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions on the test set\n",
    "test_pred_rf = rf.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the performance of the model\n",
    "print('Accuracy:', metrics.accuracy_score(test_label, test_pred_rf))\n",
    "print('Precision:', metrics.precision_score(test_label, test_pred_rf, average='weighted'))\n",
    "print('Recall:', metrics.recall_score(test_label, test_pred_rf, average='weighted'))\n",
    "print('F1 Score:', metrics.f1_score(test_label, test_pred_rf, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting is an ensemble technique that combines several simple models, usually decision trees, to create a more powerful model. It is based on the idea of building sequential models, where each model corrects the errors of the previous one.\n",
    "How does it work?\n",
    "\n",
    "- Iterative construction:\n",
    "At each iteration, a new model is added that reduces the residual (error) of the previous model.\n",
    "This is done by optimising an objective function (e.g. log-loss by classification).\n",
    "\n",
    "- Model weighing:\n",
    "Each successive model is weighted so that the hard errors of the previous model matter more.\n",
    "\n",
    "- Learning Rate:\n",
    "Controls the amount of correction that each additional model brings. A low learning rate increases accuracy, but requires more iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base model definition\n",
    "base_model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric=\"logloss\")\n",
    "# ypothetical hyperparameter space\n",
    "hyperparameters = {\n",
    "    \"n_estimators\": [25, 100, 250], #Number of trees in the forest\n",
    "    \"max_depth\": [2, 3], #Maximum depth of trees\n",
    "    \"learning_rate\": [1, 0.1, 0.001], #Update weight per iteration\n",
    "    \"subsample\": [0.8, 1.0] #Percentage of data used in each tree\n",
    "}\n",
    "\n",
    "#Random search for tuning hyperparameters\n",
    "search = RandomizedSearchCV(base_model, hyperparameters, cv=5, n_iter=10, random_state=42, scoring=\"f1_weighted\")\n",
    "\n",
    "#Training the model using the training set\n",
    "search.fit(train_set, train_label)\n",
    "\n",
    "#Best model found\n",
    "clf = search.best_estimator_\n",
    "\n",
    "#Training on the training set with the best model\n",
    "clf.fit(train_set, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction on test set\n",
    "test_pred_xgb = clf.predict(test_set)\n",
    "\n",
    "#Prediction of the model\n",
    "print(classification_report(\n",
    "    test_label, \n",
    "    test_pred_xgb, \n",
    "    target_names=['Non Top 20', 'Top 20']\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final comparisons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dizionario contenente i modelli allenati\n",
    "models = {\n",
    "    \"Decision Tree\": dt,           # Modello ad albero decisionale\n",
    "    \"Random Forest\": rf,           # Modello Random Forest\n",
    "    \"Gradient Boosting\": clf       # Modello Gradient Boosting\n",
    "}\n",
    "\n",
    "# Iterazione sui modelli per calcolare e stampare le metriche\n",
    "for model_name, model in models.items():\n",
    "    # Predizioni sul test set\n",
    "    y_test_pred = model.predict(test_set)\n",
    "    \n",
    "    # Calcolo delle metriche\n",
    "    acc = accuracy_score(test_label, y_test_pred)\n",
    "    conf = confusion_matrix(test_label, y_test_pred)\n",
    "    report = classification_report(test_label, y_test_pred, target_names=[\"Non Top 20\", \"Top 20\"])\n",
    "\n",
    "    # Output delle metriche\n",
    "    print(f\"\\n--- {model_name} ---\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{conf}\")\n",
    "    print(f\"Classification Report:\\n{report}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Come leggere i risultati**\n",
    "\n",
    "1. **`Accuracy`**:\n",
    "   - Percentuale di predizioni corrette.\n",
    "   - Utile per avere una visione generale delle performance, ma può essere ingannevole in caso di dataset sbilanciati.\n",
    "\n",
    "2. **`Confusion Matrix`**:\n",
    "   - Rappresenta visivamente i veri e falsi positivi/negativi.\n",
    "   - Ogni cella indica:\n",
    "     - **TN (0,0)**: Predizioni corrette per \"Non Top 20\".\n",
    "     - **FP (0,1)**: Predizioni errate classificate come \"Top 20\".\n",
    "     - **FN (1,0)**: Predizioni errate classificate come \"Non Top 20\".\n",
    "     - **TP (1,1)**: Predizioni corrette per \"Top 20\".\n",
    "   - Ti aiuta a identificare dove il modello sbaglia maggiormente.\n",
    "\n",
    "3. **`Classification Report`**:\n",
    "   - **Precision**:\n",
    "     - Percentuale di predizioni corrette su tutte quelle fatte per una classe.\n",
    "     - Formula: \\( \\text{Precision} = \\frac{TP}{TP + FP} \\).\n",
    "     - Elevata precisione indica pochi falsi positivi.\n",
    "   - **Recall (Sensibilità)**:\n",
    "     - Percentuale di veri positivi catturati dal modello.\n",
    "     - Formula: \\( \\text{Recall} = \\frac{TP}{TP + FN} \\).\n",
    "     - Elevato recall indica pochi falsi negativi.\n",
    "   - **F1-score**:\n",
    "     - Media armonica di precision e recall, utile per bilanciare i due aspetti.\n",
    "     - Formula: \\( \\text{F1-score} = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}} \\).\n",
    "   - **Support**:\n",
    "     - Numero di campioni effettivi per ogni classe.\n",
    "\n",
    "---\n",
    "\n",
    " **Esempio di interpretazione**\n",
    "\n",
    "Supponiamo che l'output del modello Gradient Boosting sia:\n",
    "\n",
    "```\n",
    "--- Gradient Boosting ---\n",
    "Accuracy: 0.85\n",
    "Confusion Matrix:\n",
    "[[180  20]\n",
    " [ 15  85]]\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "Non Top 20       0.92      0.90      0.91       200\n",
    "    Top 20       0.81      0.85      0.83       100\n",
    "```\n",
    "\n",
    "- **Accuracy**: 85%, cioè l'85% delle predizioni sono corrette.\n",
    "- **Confusion Matrix**:\n",
    "  - **180 TN**: \"Non Top 20\" predetto correttamente.\n",
    "  - **20 FP**: Predetto \"Top 20\", ma in realtà \"Non Top 20\".\n",
    "  - **15 FN**: Predetto \"Non Top 20\", ma in realtà \"Top 20\".\n",
    "  - **85 TP**: \"Top 20\" predetto correttamente.\n",
    "- **Classification Report**:\n",
    "  - Per la classe \"Non Top 20\":\n",
    "    - Precision: 92% (pochi FP).\n",
    "    - Recall: 90% (pochi FN).\n",
    "  - Per la classe \"Top 20\":\n",
    "    - Precision: 81% (più FP).\n",
    "    - Recall: 85% (meno FN).\n",
    "\n",
    "In questo caso, puoi confrontare le metriche tra i modelli per scegliere quello con il miglior bilanciamento di precision e recall per il tuo scopo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation and configuration of the SVM model\n",
    "svm = SVC(\n",
    "    kernel=\"sigmoid\", #Kernel used to separate data\n",
    "    C=0.5, #Penalisation for classification errors\n",
    "    gamma=\"scale\", #Influence of a single example on the model\n",
    "    probability=True #Enable probability prediction\n",
    ")\n",
    "\n",
    "#Model training\n",
    "svm.fit(train_set, train_label)\n",
    "\n",
    "#Prediction of probabilities on test set\n",
    "test_pred_proba_svm = svm.predict_proba(test_set)\n",
    "\n",
    "#Prediction of classes on the test set\n",
    "test_pred_svm = svm.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model performance output\n",
    "print(\"Predizioni di probabilità:\\n\", test_pred_proba_svm[:5])  #First 5 probabilities\n",
    "print(\"\\nPredizioni delle classi:\\n\", test_pred_svm[:5])        #First 5 predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculation of performance metrics\n",
    "print(\"\\n--- SVM Classification Report ---\")\n",
    "print(classification_report(test_label, test_pred_svm, target_names=[\"Non Top 20\", \"Top 20\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix\n",
    "conf_matrix = confusion_matrix(test_label, test_pred_svm)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating and training the Naïve Bayes model\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(train_set, train_label)\n",
    "\n",
    "#Prediction on test data\n",
    "test_pred_gnb = gnb.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation of model performance\n",
    "print(\"\\nNaïve Bayes Classifier\")\n",
    "print(classification_report(test_label, test_pred_gnb, target_names=[\"Non Top 20\", \"Top 20\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix\n",
    "conf_matrix = confusion_matrix(test_label, test_pred_gnb)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_neighbors=3: Considera i 3 vicini più prossimi per classificare un nuovo campione.\n",
    "algorithm='ball_tree': Algoritmo che ottimizza la ricerca dei vicini più prossimi.\n",
    "metric='minkowski': Misura la distanza Euclidea tra campioni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definizione del modello KNN con 3 vicini e algoritmo 'ball_tree'\n",
    "knn = KNeighborsClassifier(n_neighbors=3, algorithm='ball_tree', metric='minkowski')\n",
    "\n",
    "# Addestrare KNN sui dati di training\n",
    "knn.fit(train_set, train_label)\n",
    "\n",
    "# Prevedere sui dati di test\n",
    "test_pred_knn = knn.predict(test_set)\n",
    "\n",
    "# Valutare le performance del modello\n",
    "print(\"\\n K-Nearest Neighbors Classifier\")\n",
    "print(classification_report(test_label, test_pred_knn, target_names=[\"Non Top 20\", \"Top 20\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix\n",
    "conf_matrix = confusion_matrix(test_label, test_pred_knn)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to NumPy arrays\n",
    "y_train = np.asarray(train_label).astype('float32').reshape((-1, 1))\n",
    "y_test = np.asarray(test_label).astype('float32').reshape((-1, 1))\n",
    "\n",
    "# Define the neural network model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(x_train.shape[1],)),\n",
    "    tf.keras.layers.Dropout(0.2),  # Prevent overfitting\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',  # For binary classification\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_set, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,  # Use 20% of training data for validation\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(train_set, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation accuracy\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, acc, 'bo-', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'ro-', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, 'bo-', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'ro-', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "test_pred_proba = model.predict(train_set)\n",
    "test_pred = (test_pred_proba > 0.5).astype('int32')\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, test_pred, target_names=[\"Non Top 20\", \"Top 20\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, test_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Non Top 20\", \"Top 20\"])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule based "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ripper = lw.RIPPER()\n",
    "param_grid = {\"prune_size\": [0.5, 0.6], \"k\": [1, 3, 5]}\n",
    "grid_search = GridSearchCV(estimator=ripper, param_grid=param_grid, scoring='accuracy', cv=5)\n",
    "\n",
    "grid_search.fit(train_set, train_label)\n",
    "\n",
    "# Display the best configuration\n",
    "print('Best parameters setting:', grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for RIPPER\n",
    "import wittgenstein as lw\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "ripper = lw.RIPPER()\n",
    "param_grid = {\"prune_size\": [0.5, 0.6], \"k\": [1, 3, 5]}\n",
    "grid_search = GridSearchCV(estimator=ripper, param_grid=param_grid, scoring='accuracy', cv=5)\n",
    "\n",
    "grid_search.fit(train_set, train_label)\n",
    "\n",
    "# Display the best configuration\n",
    "print('Best parameters setting:', grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "test_pred = ripper.predict(test_set)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(test_label, test_pred))\n",
    "print(\"Precision:\", precision_score(test_label, test_pred))\n",
    "print(\"Recall:\", recall_score(test_label, test_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(test_label, test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatter Plot for Predictions\n",
    "plt.scatter(test_set.iloc[:, 0], test_set.iloc[:, 1], c=test_pred, cmap='RdBu', s=25)\n",
    "plt.title('Rule-Based Predictions (Test Set)')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.colorbar(label='Predicted Class')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison between all models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **ROC curve**: Displays the relationship between the True Positive Rate and the False Positive Rate. A curve closer to the upper left corner indicates better performance.\n",
    "\n",
    "- **AUC (Area Under Curve)**: A higher AUC value indicates a better predictive ability of the model. The maximum value is 1 (perfect classifier), while 0.5 indicates a random model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(0).clf()\n",
    "\n",
    "# Decision Tree\n",
    "fpr, tpr, thresh = metrics.roc_curve(test_label, test_pred_dt)\n",
    "auc = metrics.roc_auc_score(test_label, test_pred_dt)\n",
    "plt.plot(fpr, tpr, label=\"DecisionTree, auc=\" + str(round(auc, 3)))\n",
    "\n",
    "# Naive Bayes\n",
    "fpr, tpr, thresh = metrics.roc_curve(test_label, test_pred_gnb)\n",
    "auc = metrics.roc_auc_score(test_label, test_pred_gnb)\n",
    "plt.plot(fpr, tpr, label=\"Naive Bayes, auc=\" + str(round(auc, 3)))\n",
    "\n",
    "# XGBoost\n",
    "fpr, tpr, thresh = metrics.roc_curve(test_label, test_pred_xgb)\n",
    "auc = metrics.roc_auc_score(test_label, test_pred_xgb)\n",
    "plt.plot(fpr, tpr, label=\"XGBoost Classifier, auc=\" + str(round(auc, 3)))\n",
    "\n",
    "# Random Forest\n",
    "fpr, tpr, thresh = metrics.roc_curve(test_label, test_pred_rf)\n",
    "auc = metrics.roc_auc_score(test_label, test_pred_rf)\n",
    "plt.plot(fpr, tpr, label=\"RandomForest, auc=\" + str(round(auc, 3)))\n",
    "\n",
    "# K-Nearest Neighbor\n",
    "fpr, tpr, thresh = metrics.roc_curve(test_label, test_pred_knn)\n",
    "auc = metrics.roc_auc_score(test_label, test_pred_knn)\n",
    "plt.plot(fpr, tpr, label=\"KNN, auc=\" + str(round(auc, 3)))\n",
    "\n",
    "# Support Vector Machine\n",
    "fpr, tpr, thresh = metrics.roc_curve(test_label, test_pred_svm)\n",
    "auc = metrics.roc_auc_score(test_label, test_pred_svm)\n",
    "plt.plot(fpr, tpr, label=\"SVM, auc=\" + str(round(auc, 3)))\n",
    "\n",
    "# Neural Network\n",
    "test_pred_nn = model.predict(test_set).ravel()  # Previsione delle probabilità per la rete neurale\n",
    "fpr, tpr, thresh = metrics.roc_curve(test_label, test_pred_nn)\n",
    "auc = metrics.roc_auc_score(test_label, test_pred_nn)\n",
    "plt.plot(fpr, tpr, label=\"Neural Network, auc=\" + str(round(auc, 3)))\n",
    "\n",
    "# Rule-Based\n",
    "test_pred_rb = ripper.predict_proba(test_set)[:, 1]  # Previsione delle probabilità con RIPPER\n",
    "fpr, tpr, thresh = metrics.roc_curve(test_label, test_pred_rb)\n",
    "auc = metrics.roc_auc_score(test_label, test_pred_rb)\n",
    "plt.plot(fpr, tpr, label=\"Rule-Based, auc=\" + str(round(auc, 3)))\n",
    "\n",
    "# Layout\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Confronto delle Curve ROC')\n",
    "plt.legend(loc=0)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
