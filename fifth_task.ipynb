{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fifth Task: Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import of the needed libraries and the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "import pydotplus \n",
    "from IPython.display import Image  \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cyclists = pd.read_csv('./dataset/cyclists_trasformed.csv')\n",
    "races = pd.read_csv('./dataset/races_trasformed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CHATGPT`:\n",
    "\n",
    "Per affrontare il prossimo assignment, dovrai focalizzarti sulle spiegazioni dei modelli costruiti in precedenza. Questo include l'analisi delle feature più importanti, delle regole che il modello utilizza per fare previsioni, e dei controfattuali, ossia come cambiare gli input per modificare il risultato del modello. Ecco un piano passo-passo per affrontare l'assegnamento:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Feature Importance**\n",
    "- **Obiettivo:** Identificare quali variabili influenzano maggiormente il modello.\n",
    "- **Cosa fare:**\n",
    "  - Per modelli ad albero come Random Forest, XGBoost, e Decision Tree, usa attributi come `.feature_importances_` per visualizzare l'importanza delle feature.\n",
    "  - Per modelli lineari o SVM con kernel lineare, osserva i coefficienti dei pesi delle feature.\n",
    "  - Per le reti neurali, utilizza tecniche come **SHAP (SHapley Additive exPlanations)** o **LIME (Local Interpretable Model-agnostic Explanations)** per interpretare le feature.\n",
    "- **Come interpretare:**\n",
    "  - Verifica se le feature più importanti evidenziate dai modelli corrispondono a quanto scoperto durante la fase di data understanding e clustering. \n",
    "  - Cerca conferme di pattern noti, come ad esempio se la qualità del ciclista o il profilo delle gare sono determinanti per la posizione in classifica.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Rule Explanation**\n",
    "- **Obiettivo:** Esplicita le regole decisionali del modello.\n",
    "- **Cosa fare:**\n",
    "  - Per il modello rule-based (RIPPER), utilizza `.out_model()` per visualizzare le regole.\n",
    "  - Per modelli come Decision Tree, esporta e visualizza la struttura dell'albero decisionale usando strumenti come `plot_tree` o `graphviz`.\n",
    "  - Per Random Forest e XGBoost, combina la visualizzazione delle regole con l'importanza delle feature.\n",
    "- **Come interpretare:**\n",
    "  - Analizza se le regole create dal modello sono coerenti con i pattern logici e con i risultati della fase di analisi.\n",
    "  - Cerca regole contro-intuitive o insensate che potrebbero indicare overfitting o bias nei dati.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Counterfactual Instances**\n",
    "- **Obiettivo:** Identificare come cambiare gli input per alterare la previsione.\n",
    "- **Cosa fare:**\n",
    "  - Genera controfattuali usando librerie come **Alibi** o **DiCE (Diverse Counterfactual Explanations)**.\n",
    "  - Analizza gli input per cui il modello non prevede un risultato desiderato (es. non in top 20) e valuta quali cambiamenti li porterebbero a raggiungerlo.\n",
    "- **Come interpretare:**\n",
    "  - Valuta se i controfattuali sono sensati e realisticamente attuabili. Ad esempio, suggerire che un ciclista cambi la sua altezza per migliorare il ranking non è praticabile.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Analisi delle Spiegazioni**\n",
    "Confronta le spiegazioni in base a:\n",
    "- **Proprietà proprie:**\n",
    "  - **Fedeltà (fidelity):** Le spiegazioni rispecchiano accuratamente il comportamento del modello?\n",
    "  - **Complessità (complexity):** Le spiegazioni sono comprensibili o troppo complesse? Le regole hanno una lunghezza accettabile? Le feature più importanti sono intuitive?\n",
    "- **Relazione con Data Understanding e Clustering:**\n",
    "  - Confronta le spiegazioni con le osservazioni derivanti dall'analisi esplorativa dei dati e dal clustering. \n",
    "  - Verifica:\n",
    "    - Se il modello ha imparato gli stessi pattern evidenziati nell’analisi dei dati (es. nazionalità, peso/altezza).\n",
    "    - Se ci sono nuovi pattern non considerati precedentemente.\n",
    "    - Se ci sono pattern insensati o non attesi.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Documentazione**\n",
    "- **Report delle Spiegazioni:** Scrivi una documentazione chiara che includa:\n",
    "  - Visualizzazioni (grafici di importanza delle feature, regole estratte, controfattuali).\n",
    "  - Confronti qualitativi e quantitativi tra i modelli.\n",
    "  - Commenti su pattern emersi e loro coerenza con l'analisi precedente.\n",
    "  - Considerazioni su eventuali limiti dei modelli o problematiche nei dati.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Alternative: Usare %run\n",
    "Se preferisci mantenere il file originale come notebook (fourth_task.ipynb) senza convertirlo in .py, puoi eseguire direttamente il file Jupyter con il comando %run.\n",
    "\n",
    "Esempio:\n",
    "\n",
    "Nel file fifth_task.ipynb, esegui:\n",
    "\n",
    "# Esegui il notebook fourth_task.ipynb\n",
    "%run fourth_task.ipynb\n",
    "\n",
    "# Ora puoi usare i modelli e le variabili definiti in fourth_task.ipynb\n",
    "test_pred_dt = dt.predict(x_test)\n",
    "test_pred_rf = rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supponiamo di avere un Random Forest addestrato: dt\n",
    "feature_importance = pd.Series(dt.feature_importances_, index=x_train.columns)\n",
    "feature_importance = feature_importance.sort_values(ascending=False)\n",
    "\n",
    "# Visualizzazione\n",
    "feature_importance.plot(kind='bar', title=\"Feature Importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rule explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rule explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rule explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naïve Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rule explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counterfactual instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rule explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counterfactual instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rule explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counterfactual instances"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
